{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means to classify users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spotipy\n",
    "import sys\n",
    "import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id='653cfed9a26e46dca3e3e211ded03c0f',\\\n",
    "                                                      client_secret='a14b7886714c41c383458b26434d60cc')\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "import spotipy\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import scipy.sparse as ssp\n",
    "from collections import Counter, defaultdict\n",
    "import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.stats import pearsonr\n",
    "from __future__ import print_function    \n",
    "import time\n",
    "from scipy import stats as sss\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pickle\n",
    "from scipy import io\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #read\n",
    "train = pd.read_csv('/Users/osx/Desktop/Warner Music Dissertation/Code/train_supervised.csv')\n",
    "train = train.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_label = train['ratings']\n",
    "x_input = train.drop('ratings',axis=1)\n",
    "x_user = x_input.drop('customer_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = pd.DataFrame(2017-train['birth_year'].values)\n",
    "train = pd.concat([train,age],axis=1)\n",
    "train.rename(columns={0:'age'},inplace=True)\n",
    "train.drop('birth_year',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.sort_values('customer_id',inplace=True)\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user, index = np.unique(train['customer_id'].values,True)\n",
    "customer = np.split(train['customer_id'].values,index[1:])\n",
    "\n",
    "acout = np.split(train['acousticness'].values,index[1:])\n",
    "rat = np.split(train['ratings'].values,index[1:])\n",
    "danceability = np.split(train['danceability'].values,index[1:])\n",
    "duration = np.split(train['duration_ms'].values,index[1:])\n",
    "energy = np.split(train['energy'].values,index[1:])\n",
    "instrumentalness = np.split(train['instrumentalness'].values,index[1:])\n",
    "key = np.split(train['key'].values,index[1:])\n",
    "liveness = np.split(train['liveness'].values,index[1:])\n",
    "loudness = np.split(train['loudness'].values,index[1:])\n",
    "mode = np.split(train['mode'].values,index[1:])\n",
    "speechiness = np.split(train['speechiness'].values,index[1:])\n",
    "tempo = np.split(train['tempo'].values,index[1:])\n",
    "time_signature = np.split(train['time_signature'].values,index[1:])\n",
    "valence = np.split(train['valence'].values,index[1:])\n",
    "age = np.split(train['age'].values,index[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:03<00:00, 6653.89it/s]\n"
     ]
    }
   ],
   "source": [
    "cluster_X = []\n",
    "for i in tqdm.tqdm(range(20000)):\n",
    "    rat_ = rat[i]\n",
    "    acout_ = np.sum((acout[i]*rat[i])/np.sum(rat[i]))\n",
    "    danceability_ = np.sum((danceability[i]*rat[i])/np.sum(rat[i]))\n",
    "    duration_ = np.sum((duration[i]*rat[i])/np.sum(rat[i]))\n",
    "    energy_ = np.sum((energy[i]*rat[i])/np.sum(rat[i]))\n",
    "    instrumentalness_ = np.sum((instrumentalness[i]*rat[i])/np.sum(rat[i]))\n",
    "    key_ = np.sum((key[i]*rat[i])/np.sum(rat[i]))\n",
    "    liveness_ = np.sum((liveness[i]*rat[i])/np.sum(rat[i]))\n",
    "    loudness_ = np.sum((loudness[i]*rat[i])/np.sum(rat[i]))\n",
    "    mode_ = np.sum((mode[i]*rat[i])/np.sum(rat[i]))\n",
    "    speechiness_ = np.sum((speechiness[i]*rat[i])/np.sum(rat[i]))\n",
    "    tempo_ = np.sum((tempo[i]*rat[i])/np.sum(rat[i]))\n",
    "    time_signature_ = np.sum((time_signature[i]*rat[i])/np.sum(rat[i]))\n",
    "    valence_ = np.sum((valence[i]*rat[i])/np.sum(rat[i]))\n",
    "    age_ = np.sum((age[i]*rat[i])/np.sum(rat[i]))\n",
    "    cluster_X.append(np.array([acout_,danceability_,duration_,energy_,instrumentalness_,key_,liveness_,loudness_,mode_,\\\n",
    "                               speechiness_,tempo_,time_signature_,valence_,age_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, random_state=0).fit(cluster_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_1 = np.array(np.where(kmeans.labels_==0))[0]\n",
    "group_2 = np.array(np.where(kmeans.labels_==1))[0]\n",
    "group_3 = np.array(np.where(kmeans.labels_==2))[0]\n",
    "group_4 = np.array(np.where(kmeans.labels_==3))[0]\n",
    "group_5 = np.array(np.where(kmeans.labels_==4))[0]\n",
    "group_6 = np.array(np.where(kmeans.labels_==5))[0]\n",
    "# group_7 = np.array(np.where(kmeans.labels_==6))[0]\n",
    "# group_8 = np.array(np.where(kmeans.labels_==7))[0]\n",
    "# group_9 = np.array(np.where(kmeans.labels_==8))[0]\n",
    "# group_10 = np.array(np.where(kmeans.labels_==9))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 77.55it/s]\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for j in tqdm.tqdm([group_1,group_2,group_3,group_4,group_5,group_6]):\n",
    "    k+=1\n",
    "    group_list = []\n",
    "    for i in j:\n",
    "        group_list.append(customer[i][0])\n",
    "    if k==1:\n",
    "        group_df_1 = train[train.customer_id.isin(group_list)]\n",
    "    if k==2:\n",
    "        group_df_2 = train[train.customer_id.isin(group_list)]\n",
    "    if k==3:\n",
    "        group_df_3 = train[train.customer_id.isin(group_list)]\n",
    "    if k==4:\n",
    "        group_df_4 = train[train.customer_id.isin(group_list)]\n",
    "    if k==5:\n",
    "        group_df_5 = train[train.customer_id.isin(group_list)]\n",
    "    if k==6:\n",
    "        group_df_6 = train[train.customer_id.isin(group_list)]\n",
    "#     if k==7:\n",
    "#         group_df_7 = train[train.customer_id.isin(group_list)]\n",
    "#     if k==8:\n",
    "#         group_df_8 = train[train.customer_id.isin(group_list)]\n",
    "#     if k==9:\n",
    "#         group_df_9 = train[train.customer_id.isin(group_list)]\n",
    "#     if k==10:\n",
    "#         group_df_10 = train[train.customer_id.isin(group_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_1 = group_df_1['ratings']\n",
    "customer_1=group_df_1['customer_id']\n",
    "y_2 = group_df_2['ratings']\n",
    "customer_2=group_df_2['customer_id']\n",
    "y_3 = group_df_3['ratings']\n",
    "customer_3=group_df_3['customer_id']\n",
    "y_4 = group_df_4['ratings']\n",
    "customer_4=group_df_4['customer_id']\n",
    "y_5 = group_df_5['ratings']\n",
    "customer_5=group_df_5['customer_id']\n",
    "y_6 = group_df_6['ratings']\n",
    "customer_6=group_df_6['customer_id']\n",
    "y = train['ratings']\n",
    "# y_7 = group_df_7['ratings']\n",
    "# customer_7=group_df_7['customer_id']\n",
    "# y_8 = group_df_8['ratings']\n",
    "# customer_8=group_df_8['customer_id']\n",
    "# y_9 = group_df_9['ratings']\n",
    "# customer_9=group_df_9['customer_id']\n",
    "# y_10 = group_df_10['ratings']\n",
    "# customer_10=group_df_10['customer_id']\n",
    "\n",
    "features_to_drop=['customer_id', 'artist_name', 'track_name', 'album_name','ratings']\n",
    "group_df_1.drop(features_to_drop,axis=1,inplace=True)\n",
    "group_df_2.drop(features_to_drop,axis=1,inplace=True)\n",
    "group_df_3.drop(features_to_drop,axis=1,inplace=True)\n",
    "group_df_4.drop(features_to_drop,axis=1,inplace=True)\n",
    "group_df_5.drop(features_to_drop,axis=1,inplace=True)\n",
    "group_df_6.drop(features_to_drop,axis=1,inplace=True)\n",
    "train.drop(features_to_drop,axis=1,inplace=True)\n",
    "# group_df_7.drop(features_to_drop,axis=1,inplace=True)\n",
    "# group_df_8.drop(features_to_drop,axis=1,inplace=True)\n",
    "# group_df_9.drop(features_to_drop,axis=1,inplace=True)\n",
    "# group_df_10.drop(features_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_to_tuned = {'max_depth':[3,6,8],\n",
    "                  'n_estimators':[500,700,300],\n",
    "                  'min_samples_split':[3,5,10],\n",
    "                  'min_samples_leaf':[1,3],\n",
    "                  'min_weight_fraction_leaf':[0],\n",
    "                  'max_leaf_nodes':[None],\n",
    "                  'oob_score':[False],\n",
    "                  'bootstrap':[True],\n",
    "                  'class_weight':['balanced']}\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "rfr_model = RandomForestRegressor()    \n",
    "rfr_Model = GridSearchCV(rfc_model, param_grid = param_to_tuned,cv=10,refit=True,return_train_score=True)\n",
    "RFR = rfr_Model.fit(train, y)\n",
    "\n",
    "RFR_1 = rfr_Model.fit(group_df_1,y_1)\n",
    "RFR_2 = rfr_Model.fit(group_df_2,y_2)\n",
    "RFR_3 = rfr_Model.fit(group_df_3,y_3)\n",
    "RFR_4 = rfr_Model.fit(group_df_4,y_4)\n",
    "RFR_5 = rfr_Model.fit(group_df_5,y_5)\n",
    "RFR_6 = rfr_Model.fit(group_df_6,y_6)\n",
    "\n",
    "delta = time.time() - start\n",
    "\n",
    "print('model training time:',round((time.time()-t)/60,3),'minutes\\n')\n",
    "print('optimal parameter:')\n",
    "print('max_depth:',rfc_Model.best_params_['max_depth'])\n",
    "print('n_estimators:',rfc_Model.best_params_['n_estimators'])\n",
    "print('min_samples_split:',rfc_Model.best_params_['min_samples_split'])\n",
    "print('min_samples_leaf:',rfc_Model.best_params_['min_samples_leaf'])\n",
    "print (\"model trained finished in %.2f seconds\" % (delta,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained finished in 60.48 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "RFR = RandomForestRegressor(max_depth=5,n_estimators=300)\n",
    "RFR_1 = RFR.fit(group_df_1,y_1)\n",
    "RFR_2 = RFR.fit(group_df_2,y_2)\n",
    "RFR_3 = RFR.fit(group_df_3,y_3)\n",
    "RFR_4 = RFR.fit(group_df_4,y_4)\n",
    "RFR_5 = RFR.fit(group_df_5,y_5)\n",
    "RFR_6 = RFR.fit(group_df_6,y_6)\n",
    "# RFR_7 = RFR.fit(group_df_7,y_7)\n",
    "# RFR_8 = RFR.fit(group_df_8,y_8)\n",
    "# RFR_9 = RFR.fit(group_df_9,y_9)\n",
    "# RFR_10 = RFR.fit(group_df_10,y_10)\n",
    "delta = time.time() - start\n",
    "print (\"model trained finished in %.2f seconds\" % (delta,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### linear SVM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_to_tuned = {'kernel':['rbf','linear','sigmoid'], \n",
    "                  'degree':[3], 'gamma':['auto'],\n",
    "                  'max_iter':[-1,'solver']}\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "SVR_model = svm.SVR()\n",
    "svr_Model = GridSearchCV(SVR_model, param_grid = param_to_tuned,cv=10,refit=True,return_train_score=True)\n",
    "SVR = svr_Model.fit(train, y)\n",
    "\n",
    "SVR_1 = svr_Model.fit(group_df_1,y_1)\n",
    "SVR_2 = svr_Model.fit(group_df_2,y_2)\n",
    "SVR_3 = svr_Model.fit(group_df_3,y_3)\n",
    "SVR_4 = svr_Model.fit(group_df_4,y_4)\n",
    "SVR_5 = svr_Model.fit(group_df_5,y_5)\n",
    "SVR_6 = svr_Model.fit(group_df_6,y_6)\n",
    "\n",
    "delta = time.time() - start\n",
    "print (\"model trained finished in %.2f seconds\" % (delta,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_to_tuned = {'max_depth':[3,6,8],\n",
    "                  'seed':[1337],\n",
    "                  'silent':[1],\n",
    "                  'n_estimators':[500,700,300],\n",
    "                  'learning_rate':np.linspace(0.01,0.6,6),\n",
    "                  'subsample':[0.1,0.8],\n",
    "                  'colsample_bytree':[0.7],\n",
    "                  'gamma':[0,1,0.5],\n",
    "                  'min_child_weight':[0,0.5,1.5]}\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "xgb_model = xgb.XGBRegressor()    \n",
    "XGB_Model = GridSearchCV(xgb_model, param_grid = param_to_tuned, scoring='neg_mean_absolute_error',\\\n",
    "                         cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=None),\\\n",
    "                          refit=True,return_train_score=True)\n",
    "t = time.time()\n",
    "XGB = XGB_Model.fit(train, y)\n",
    "\n",
    "# SVR_1 = XGB_Model.fit(group_df_1,y_1)\n",
    "# SVR_2 = XGB_Model.fit(group_df_2,y_2)\n",
    "# SVR_3 = XGB_Model.fit(group_df_3,y_3)\n",
    "# SVR_4 = XGB_Model.fit(group_df_4,y_4)\n",
    "# SVR_5 = XGB_Model.fit(group_df_5,y_5)\n",
    "# SVR_6 = XGB_Model.fit(group_df_6,y_6)\n",
    "\n",
    "delta = time.time() - start\n",
    "print (\"model trained finished in %.2f seconds\" % (delta,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_to_tuned = {'alpha':[1.0,0.5,0.01],\n",
    "                  'normalize':[False,True],\n",
    "                  }\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "ridge_model = Ridge(alpha=1.0, fit_intercept=True, normalize=False,\\\n",
    "                    copy_X=True, max_iter=None, tol=0.001, \\\n",
    "                    solver=’auto’, random_state=None)\n",
    "\n",
    "   \n",
    "ridge_Model = GridSearchCV(ridge_model, param_grid = param_to_tuned, scoring='rmse',\\\n",
    "                         cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=None),\\\n",
    "                          refit=True,return_train_score=True)\n",
    "t = time.time()\n",
    "Ridge = ridge_Model.fit(train, y)\n",
    "\n",
    "Ridge_1 = ridge_Model.fit(group_df_1,y_1)\n",
    "Ridge_2 = ridge_Model.fit(group_df_2,y_2)\n",
    "Ridge_3 = ridge_Model.fit(group_df_3,y_3)\n",
    "Ridge_4 = ridge_Model.fit(group_df_4,y_4)\n",
    "Ridge_5 = ridge_Model.fit(group_df_5,y_5)\n",
    "Ridge_6 = ridge_Model.fit(group_df_6,y_6)\n",
    "\n",
    "delta = time.time() - start\n",
    "print (\"model trained finished in %.2f seconds\" % (delta,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained finished in 22.92 seconds\n"
     ]
    }
   ],
   "source": [
    "param_to_tuned = {'n_components':[256,150,300],\n",
    "                  'learning_rate':[0.1,0.5,0.6],\n",
    "                  'batch_size':[10,50,5],\n",
    "                  'n_iter':[10,6,15],\n",
    "                  }\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "RBM_model = BernoulliRBM()\n",
    "RBM_Model = GridSearchCV(RBM_model, param_grid = param_to_tuned, scoring='rmse',\\\n",
    "                         cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=None),\\\n",
    "                          refit=True,return_train_score=True)\n",
    "rbm = RBM_Model.fit(train,y)\n",
    "\n",
    "rbm_1 = RBM_Model.fit(group_df_1,y_1)\n",
    "rbm_2 = RBM_Model.fit(group_df_2,y_2)\n",
    "rbm_3 = RBM_Model.fit(group_df_3,y_3)\n",
    "rbm_4 = RBM_Model.fit(group_df_4,y_4)\n",
    "rbm_5 = RBM_Model.fit(group_df_5,y_5)\n",
    "rbm_6 = RBM_Model.fit(group_df_6,y_6)\n",
    "\n",
    "delta = time.time() - start\n",
    "print (\"model trained finished in %.2f seconds\" % (delta,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_to_tuned = {'hidden_layer_sizes':[(100,200,300),(150,300,500)],\n",
    "                  'activation':['relu','logistic'],\n",
    "                  'learning_rate_init':[0.0001,0.0005,0.001],\n",
    "                  'max_iter':[200,300,500],\n",
    "                  }\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "NN_model = MLPRegressor(solver=’adam’,\\\n",
    "                        alpha=0.0001, batch_size=’auto’,\\\n",
    "                        shuffle=True,random_state=None, tol=0.0001, verbose=False, warm_start=False)\n",
    "NN_Model = GridSearchCV(NN_model, param_grid = param_to_tuned, scoring='rmse',\\\n",
    "                         cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=None),\\\n",
    "                          refit=True,return_train_score=True)\n",
    "nn = NN_Model.fit(train,y)\n",
    "\n",
    "nn_1 = NN_Model.fit(group_df_1,y_1)\n",
    "nn_2 = NN_Model.fit(group_df_2,y_2)\n",
    "nn_3 = NN_Model.fit(group_df_3,y_3)\n",
    "nn_4 = NN_Model.fit(group_df_4,y_4)\n",
    "nn_5 = NN_Model.fit(group_df_5,y_5)\n",
    "nn_6 = NN_Model.fit(group_df_6,y_6)\n",
    "\n",
    "delta = time.time() - start\n",
    "print (\"model trained finished in %.2f seconds\" % (delta,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering part of recommended tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_recommend = pd.read_csv('/Users/osx/Desktop/Warner Music Dissertation/Code/test_supervised.csv')\n",
    "raw_recommend = raw_recommend.drop('Unnamed: 0',axis=1)\n",
    "raw_recommend.sort_values('customer_id',inplace=True)\n",
    "raw_recommend.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = pd.DataFrame(2017-raw_recommend['birth_year'].values)\n",
    "raw_recommend = pd.concat([raw_recommend,age],axis=1)\n",
    "raw_recommend.rename(columns={0:'age'},inplace=True)\n",
    "raw_recommend.drop('birth_year',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 24.31it/s]\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "for j in tqdm.tqdm([group_1,group_2,group_3,group_4,group_5,group_6]):\n",
    "    k+=1\n",
    "    group_list = []\n",
    "    for i in j:\n",
    "        group_list.append(customer[i][0])\n",
    "    if k==1:\n",
    "        test_1 = raw_recommend[raw_recommend.customer_id.isin(group_list)]\n",
    "    if k==2:\n",
    "        test_2 = raw_recommend[raw_recommend.customer_id.isin(group_list)]\n",
    "    if k==3:\n",
    "        test_3 = raw_recommend[raw_recommend.customer_id.isin(group_list)]\n",
    "    if k==4:\n",
    "        test_4 = raw_recommend[raw_recommend.customer_id.isin(group_list)]\n",
    "    if k==5:\n",
    "        test_5 = raw_recommend[raw_recommend.customer_id.isin(group_list)]\n",
    "    if k==6:\n",
    "        test_6 = raw_recommend[raw_recommend.customer_id.isin(group_list)]\n",
    "#     if k==7:\n",
    "#         group_df_7 = train[train.customer_id.isin(group_list)]\n",
    "#     if k==8:\n",
    "#         group_df_8 = train[train.customer_id.isin(group_list)]\n",
    "#     if k==9:\n",
    "#         group_df_9 = train[train.customer_id.isin(group_list)]\n",
    "#     if k==10:\n",
    "#         group_df_10 = train[train.customer_id.isin(group_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'track_name', 'acousticness', 'danceability',\n",
       "       'duration_ms', 'energy', 'instrumentalness', 'key', 'liveness',\n",
       "       'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence',\n",
       "       'artist_name', 'album_name', 'age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_recommend.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_drop = ['customer_id', 'track_name','artist_name', 'album_name']\n",
    "raw_recommend_train = raw_recommend.drop(features_to_drop,axis=1)\n",
    "test_1 = test_1.drop(features_to_drop,axis=1)\n",
    "test_2 = test_2.drop(features_to_drop,axis=1)\n",
    "test_3 = test_3.drop(features_to_drop,axis=1)\n",
    "test_4 = test_4.drop(features_to_drop,axis=1)\n",
    "test_5 = test_5.drop(features_to_drop,axis=1)\n",
    "test_6 = test_6.drop(features_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_ft=np.load('validation_Dict.npy').item()\n",
    "active_user = np.load('active_user.npy')\n",
    "t = np.load('trainset_Dict.npy').item()\n",
    "index_to_user_dict = np.load('train_user_map.npy').item()\n",
    "index_to_track_id = np.load('train_track_map.npy').item()\n",
    "inv_track_id_map = np.load('inv_track_map.npy').item()\n",
    "track_uni_=np.load('track_feature_1.npy').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### xgboost filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/xgboost.sav'\n",
    "xgboost = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_filter = xgboost.predict(raw_recommend_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = pd.concat([raw_recommend[['customer_id','track_name']],pd.DataFrame(y_filter).rename(columns={0:'pre_ratings'})]\\\n",
    "                 ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    375000.000000\n",
       "mean          1.326602\n",
       "std           1.268441\n",
       "min           1.099403\n",
       "25%           1.264710\n",
       "50%           1.289279\n",
       "75%           1.316063\n",
       "max          58.952877\n",
       "Name: pre_ratings, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['pre_ratings'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user, index = np.unique(pred['customer_id'],True)\n",
    "rec_track = np.split(pred['track_name'],index[1:])\n",
    "pre_track = np.split(pred['pre_ratings'],index[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:16<00:00, 924.09it/s]\n"
     ]
    }
   ],
   "source": [
    "keep_ = 15\n",
    "filtered_rec = {}\n",
    "for i in tqdm.tqdm(range(15000)):\n",
    "    filtered_rec[i] = rec_track[i][pre_track[i].nlargest(keep_).index.tolist()].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tnum_val = 0\n",
    "suc_rec = 0\n",
    "num_p = 0\n",
    "for i in active_user:\n",
    "    num_val = len(v_ft[index_to_user_dict[i]].keys())\n",
    "    Tnum_val = Tnum_val+num_val\n",
    "    rec_set = filtered_rec[i]\n",
    "    num_p = num_p+len(rec_set)\n",
    "    for j in v_ft[index_to_user_dict[i]].keys():\n",
    "        if j in rec_set:\n",
    "            suc_rec+=1\n",
    "            \n",
    "recall_xgb = suc_rec/Tnum_val\n",
    "precision_xgb = suc_rec/num_p\n",
    "print('xgboost without k-means filtered recall is',recall_xgb)\n",
    "print('xgboost without k-means filtered precision is',precision_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Network with propogation filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/NeuralNetwork.sav'\n",
    "NN = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_NN = NN.predict(raw_recommend_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_NN = pd.concat([raw_recommend[['customer_id','track_name']],pd.DataFrame(y_NN).rename(columns={0:'pre_ratings'})]\\\n",
    "                 ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user, index = np.unique(pred_NN['customer_id'],True)\n",
    "rec_track = np.split(pred_NN['track_name'],index[1:])\n",
    "pre_track = np.split(pred_NN['pre_ratings'],index[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:14<00:00, 1032.60it/s]\n"
     ]
    }
   ],
   "source": [
    "keep_ = 15\n",
    "NN_filtered_rec = {}\n",
    "for i in tqdm.tqdm(range(15000)):\n",
    "    NN_filtered_rec[i] = rec_track[i][pre_track[i].nlargest(keep_).index.tolist()].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tnum_val = 0\n",
    "suc_rec = 0\n",
    "num_p = 0\n",
    "for i in active_user:\n",
    "    num_val = len(v_ft[index_to_user_dict[i]].keys())\n",
    "    Tnum_val = Tnum_val+num_val\n",
    "    rec_set = NN_filtered_rec[i]\n",
    "    num_p = num_p+len(rec_set)\n",
    "    for j in v_ft[index_to_user_dict[i]].keys():\n",
    "        if j in rec_set:\n",
    "            suc_rec+=1\n",
    "            \n",
    "recall_nn = suc_rec/Tnum_val\n",
    "precision_nn = suc_rec/num_p\n",
    "print('Neural Network without k-means filtered recall is',recall_nn)\n",
    "print('Neural Network without k-means filtered precision is',precision_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/randaomforest.sav'\n",
    "RFR = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_RFR = RFR.predict(raw_recommend_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_RFR = pd.concat([raw_recommend[['customer_id','track_name']],pd.DataFrame(y_RFR).rename(columns={0:'pre_ratings'})]\\\n",
    "                 ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user, index = np.unique(pred_RFR['customer_id'],True)\n",
    "rec_track = np.split(pred_RFR['track_name'],index[1:])\n",
    "pre_track = np.split(pred_RFR['pre_ratings'],index[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:14<00:00, 1024.18it/s]\n"
     ]
    }
   ],
   "source": [
    "keep_ = 15\n",
    "RFR_filtered_rec = {}\n",
    "for i in tqdm.tqdm(range(15000)):\n",
    "    RFR_filtered_rec[i] = rec_track[i][pre_track[i].nlargest(keep_).index.tolist()].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tnum_val = 0\n",
    "suc_rec = 0\n",
    "num_p = 0\n",
    "for i in active_user:\n",
    "    num_val = len(v_ft[index_to_user_dict[i]].keys())\n",
    "    Tnum_val = Tnum_val+num_val\n",
    "    rec_set = RFR_filtered_rec[i]\n",
    "    num_p = num_p+len(rec_set)\n",
    "    for j in v_ft[index_to_user_dict[i]].keys():\n",
    "        if j in rec_set:\n",
    "            suc_rec+=1\n",
    "            \n",
    "recall_rfr = suc_rec/Tnum_val\n",
    "precision_rfr = suc_rec/num_p\n",
    "print('Random Forest without k-means filtered recall is',recall_rfr)\n",
    "print('Random Forest without k-means filtered precision is',precision_rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### neruak network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/nn1.sav'\n",
    "nn1 = pickle.load(open(filename, 'rb'))\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/nn2.sav'\n",
    "nn2 = pickle.load(open(filename, 'rb'))\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/nn3.sav'\n",
    "nn3 = pickle.load(open(filename, 'rb'))\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/nn4.sav'\n",
    "nn4 = pickle.load(open(filename, 'rb'))\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/nn5.sav'\n",
    "nn5 = pickle.load(open(filename, 'rb'))\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/nn6.sav'\n",
    "nn6 = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_nn1 = nn1.predict(test_1)\n",
    "y_nn2 = nn2.predict(test_2)\n",
    "y_nn3 = nn3.predict(test_3)\n",
    "y_nn4 = nn4.predict(test_4)\n",
    "y_nn5 = nn5.predict(test_5)\n",
    "y_nn6 = nn6.predict(test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_1 = pd.DataFrame(y_nn1,index=test_1.index).rename(columns={0:'pre_ratings'})\n",
    "pred_2 = pd.DataFrame(y_nn2,index=test_2.index).rename(columns={0:'pre_ratings'})\n",
    "pred_3 = pd.DataFrame(y_nn3,index=test_3.index).rename(columns={0:'pre_ratings'})\n",
    "pred_4 = pd.DataFrame(y_nn4,index=test_4.index).rename(columns={0:'pre_ratings'})\n",
    "pred_5 = pd.DataFrame(y_nn5,index=test_5.index).rename(columns={0:'pre_ratings'})\n",
    "pred_6 = pd.DataFrame(y_nn6,index=test_6.index).rename(columns={0:'pre_ratings'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = pd.concat([pred_1,pred_2,pred_3,pred_4,pred_5,pred_6])\n",
    "pred = pred.reset_index().sort_values('index').reset_index()\n",
    "pred.drop(['level_0','index'],axis=1,inplace=True)\n",
    "pred_NN = pd.concat([raw_recommend[['customer_id','track_name']],pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user, index = np.unique(pred_NN['customer_id'],True)\n",
    "rec_track = np.split(pred_NN['track_name'],index[1:])\n",
    "pre_track = np.split(pred_NN['pre_ratings'],index[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:13<00:00, 1073.00it/s]\n"
     ]
    }
   ],
   "source": [
    "keep_ = 15\n",
    "NN_filtered_rec = {}\n",
    "for i in tqdm.tqdm(range(15000)):\n",
    "    NN_filtered_rec[i] = rec_track[i][pre_track[i].nlargest(keep_).index.tolist()].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tnum_val = 0\n",
    "suc_rec = 0\n",
    "num_p = 0\n",
    "for i in active_user:\n",
    "    num_val = len(v_ft[index_to_user_dict[i]].keys())\n",
    "    Tnum_val = Tnum_val+num_val\n",
    "    rec_set = NN_filtered_rec[i]\n",
    "    num_p = num_p+len(rec_set)\n",
    "    for j in v_ft[index_to_user_dict[i]].keys():\n",
    "        if j in rec_set:\n",
    "            suc_rec+=1\n",
    "            \n",
    "recall_nn = suc_rec/Tnum_val\n",
    "precision_nn = suc_rec/num_p\n",
    "print('Neural Network with k-means filtered recall is',recall_nn)\n",
    "print('Neural Network with k-means filtered precision is',precision_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/xgboost_1.sav'\n",
    "xgb_1 = pickle.load(open(filename, 'rb'))\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/xgboost_2.sav'\n",
    "xgb_2 = pickle.load(open(filename, 'rb'))\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/xgboost_3.sav'\n",
    "xgb_3 = pickle.load(open(filename, 'rb'))\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/xgboost_4.sav'\n",
    "xgb_4 = pickle.load(open(filename, 'rb'))\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/xgboost_5.sav'\n",
    "xgb_5 = pickle.load(open(filename, 'rb'))\n",
    "filename = '/Users/osx/Desktop/Warner Music Dissertation/Model/xgboost_6.sav'\n",
    "xgb_6 = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_xgb1 = xgb_1.predict(test_1)\n",
    "y_xgb2 = xgb_2.predict(test_2)\n",
    "y_xgb3 = xgb_3.predict(test_3)\n",
    "y_xgb4 = xgb_4.predict(test_4)\n",
    "y_xgb5 = xgb_5.predict(test_5)\n",
    "y_xgb6 = xgb_6.predict(test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_1 = pd.DataFrame(y_xgb1,index=test_1.index).rename(columns={0:'pre_ratings'})\n",
    "pred_2 = pd.DataFrame(y_xgb2,index=test_2.index).rename(columns={0:'pre_ratings'})\n",
    "pred_3 = pd.DataFrame(y_xgb3,index=test_3.index).rename(columns={0:'pre_ratings'})\n",
    "pred_4 = pd.DataFrame(y_xgb4,index=test_4.index).rename(columns={0:'pre_ratings'})\n",
    "pred_5 = pd.DataFrame(y_xgb5,index=test_5.index).rename(columns={0:'pre_ratings'})\n",
    "pred_6 = pd.DataFrame(y_xgb6,index=test_6.index).rename(columns={0:'pre_ratings'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = pd.concat([pred_1,pred_2,pred_3,pred_4,pred_5,pred_6])\n",
    "pred = pred.reset_index().sort_values('index').reset_index()\n",
    "pred.drop(['level_0','index'],axis=1,inplace=True)\n",
    "pred_XGB = pd.concat([raw_recommend[['customer_id','track_name']],pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user, index = np.unique(pred_XGB['customer_id'],True)\n",
    "rec_track = np.split(pred_XGB['track_name'],index[1:])\n",
    "pre_track = np.split(pred_XGB['pre_ratings'],index[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:15<00:00, 959.47it/s]\n"
     ]
    }
   ],
   "source": [
    "keep_ = 15\n",
    "XGB_filtered_rec = {}\n",
    "for i in tqdm.tqdm(range(15000)):\n",
    "    XGB_filtered_rec[i] = rec_track[i][pre_track[i].nlargest(keep_).index.tolist()].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tnum_val = 0\n",
    "suc_rec = 0\n",
    "num_p = 0\n",
    "for i in active_user:\n",
    "    num_val = len(v_ft[index_to_user_dict[i]].keys())\n",
    "    Tnum_val = Tnum_val+num_val\n",
    "    rec_set = XGB_filtered_rec[i]\n",
    "    num_p = num_p+len(rec_set)\n",
    "    for j in v_ft[index_to_user_dict[i]].keys():\n",
    "        if j in rec_set:\n",
    "            suc_rec+=1\n",
    "            \n",
    "recall_nn = suc_rec/Tnum_val\n",
    "precision_nn = suc_rec/num_p\n",
    "print('XGB with k-means filtered recall is',recall_nn)\n",
    "print('XGB with k-means filtered precision is',precision_nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
